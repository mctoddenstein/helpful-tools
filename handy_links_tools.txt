Handy Links/Tools

https://<clustermaster>:8089/services/cluster/master/buckets



convert bucket epoch times to gregorian

ls -l /opt/splunk/var/lib/splunk/defaultdb/db | fgrep db_ | sed -r s/.*\(db_\(.+\)_\(.+\)_.*\)/\\1\\n\\2\\n\\3/ | gawk '/^db/ {print $0} /^1/ {print "    " strftime("%c", $0)}'


For getting log information on search performance do the following:
1. Change $splunkhome/etc/log-searchprocess.cfg "rootCategory=INFO  --> DEBUG"
2. run problematic search
3. open job inspector and copy the SID
4. navigate to $splunkhome/var/run/splunk/dispatch
5. Copy entire SID directory
6. Look through search.log for issues
7. Revert log level
**NOTE** you do NOT need to restart for the log-searchprocess.cfg
take a diag after you have run all the searches/collected directories so you can compare load on host/network etc during the time the searches were run


Search query for blocked queues
index=_internal source=*metrics.log blocked=true

Searching for real-time searches
"dispatch.earliest_time = rt*" AND "disabled = 0"


show all apps and current status
/SPLUNK_HOME/bin/splunk display app


tcpout thruput max and average search query
index=_internal host=<inserthostnamehere> sourcetype=metrics group=tcpout_connections | eval KBps=tcp_Bps/1024 | timechart max(KBps) as MaxKBps avg(KBps) as AvgKBps



compression on disk search query

|dbinspect index=main
| where eventCount > 10000
|fields index,id,state,eventCount,rawSize,sizeOnDiskMB,sourceTypeCount
|eval TotalRawMB=(rawSize/1024/1024)
| eval compression=tostring(round(sizeOnDiskMB/TotalRawMB*100,2)) + "%"
|table index, id, state, sourceTypeCount, TotalRawMB, sizeOnDiskMB, compression


list off number of folders in a directory
find -type d -maxdepth 1 | wc -l


identify skipped searches

index=_internal source = *scheduler.log status=skipped | stats count by user app savedsearch_name status



https://answers.splunk.com/answers/327033/how-to-create-an-alert-for-a-forwarder-that-hasnt.html

 index=_internal sourcetype=splunkd group=tcpin_connections NOT eventType=*
 | stats
 max(_time) as last_connected,
 sum(kb) as sum_kb by guid, hostname
 | addinfo
 | eval status = if(isnull(sum_kb) or (sum_kb <= 0) or (last_connected < (info_max_time - 900)), "missing", "active")
 | where status="missing"



good upgrading case reference
https://splunk.my.salesforce.com/50033000010W9q9



reloading the auth services through REST endpoint

http(s)://yourserver:8000/en-US/debug/refresh?entity=admin/auth-services


License usage report and RolloverSummary
index=_internal host=<license_master_instance_name> source=*/license_usage.log* type=RolloverSummary earliest=-30d



check cron schedule in undiag backend for savedsearches.conf and when searches are running

grep " cron_schedule" savedsearches_debug.txt | cut -d' ' -s -f2 --complement | sort | uniq -c | sort -n
grep " cron_schedule" savedsearches.conf | cut -d' ' -s -f2 --complement | sort | uniq -c | sort -n


alternatively

./splunk btool savedsearches list --debug | grep " cron_schedule" | cut -d' ' -s -f2 --complement | sort | uniq -c | sort -n



One member indexer cluster

1. Make sure all the _*indexes are defined within the master apps.
2. Create small change on the master to create a new bundle.
3. Verify the CM is running.
4. Verify indexers are running; issue CLI fsck command to join the cluster.
5. Once completed please upload a diag of each instance if the work around does not resolve the issue.


HTTP response time query

index=_internal host="<yourhosthere>" source=*splunkd_access.log* NOT "/streams/" spent>999
                        | eval spent=ceiling(spent/1000)
                        | eval desc=case(spent<=1, "OKAY", spent<30, "WARNING", spent>29, "DANGER")
                        | stats count by uri_path, spent, desc, _time



check splunk to validate files

/opt/splunk/bin/splunk validate files


search for license usage by sourcetype

index=_internal source=*license_usage.log* type="Usage" | eval h=if(len(h)=0 OR isnull(h),"(SQUASHED)",h) | eval s=if(len(s)=0 OR isnull(s),"(SQUASHED)",s) | eval idx=if(len(idx)=0 OR isnull(idx),"(UNKNOWN)",idx) | stats sum(b) as b by _time, pool, s, st, h, idx | timechart limit=100 sum(b) AS volumeB by st fixedrange=false | foreach * [eval <<FIELD>>=round('<<FIELD>>'/1024/1024, 3)]


license usage by index

index=_internal [`set_local_host`] source=*license_usage.log* type="Usage" | eval h=if(len(h)=0 OR isnull(h),"(SQUASHED)",h) | eval s=if(len(s)=0 OR isnull(s),"(SQUASHED)",s) | eval idx=if(len(idx)=0 OR isnull(idx),"(UNKNOWN)",idx) | bin _time span=1d | stats sum(b) as b by _time, pool, s, st, h, idx   | timechart span=1d sum(b) AS volumeB by idx fixedrange=false  limit=0| join type=outer _time [search index=_internal [`set_local_host`] source=*license_usage.log* type="RolloverSummary" earliest=-30d@d | eval _time=_time - 43200 | bin _time span=1d | stats latest(stacksz) AS "stack size" by _time] | fields - _timediff  | foreach * [eval <<FIELD>>=round('<<FIELD>>'/1024/1024/1024, 3)]



Check input status

Browser:
https://<forwarderIP>:8089/services/admin/inputstatus/TailingProcessor:FileStatus

CLI:
./splunk list inputstatus


Forwarder Diagnostics – Last time Data Was Received by Index and Sourcetype


| tstats latest(_time) as Latest by host sourcetype index
| eval current=now()
| eval Minimum_Age=round(((current-Latest)/60)/60,2)
| rangemap field=Minimum_Age default=Critical Normal=0-0.5 Elevated=0.5-2 Warning=2-4
| eval stIDX=tostring(index) + " -- " + tostring(sourcetype)
| stats values(stIDX) as "Index -- Sourcetype" list(Latest) as "Latest Event" list(Minimum_Age) as Minimum_Age list(range) as Threshold by host bloc
| convert ctime("Latest Event")
| eventstats avg(Minimum_Age) as average by host
| eval average=round(average,2)
| sort - average
| rename Minimum_Age as "Hours Since Last Communication" average as "Average Time in Hours Since Last Communication"



List of hosts and sourcetypes not sending data in last 24 Hours

noop |append [ |metadata type=hosts | table *] | append [|metadata type=sourcetypes | table *] | eval t = now() - lastTime | where t > 86400 | eval name = coalesce(host,sourcetype)| table name t lastTime totalCount type |rename t as "Seconds since Event" | convert ctime(lastTime) timeformat="%m/%d/%Y %H:%M:%S %z"



checking for duplicate data in the index (dupes)

| stats count AS eventcount by _raw | where eventcount > 1



roll hot buckets via REST API
curl –k https://localhost:8089/services/data/indexes/[name]/roll-hot-buckets -x POST -u admin:password

link to page
https://www.batchworks.de/manually-roll-buckets-from-hot-to-warm/



Set log levels

grep -i <search term> log.cfg

./splunk show log-level <COMPONENT>

./splunk set log-level <COMPONENT> -level <LEVEL>


Bonnie test parameters

$ bonnie++ -d [/your volume] -s [twice your system RAM in MB] -u root:root -qfb


Latency between indexed time and actual time

index=_internal sourcetype=splunkd | eval latency=_indextime - _time | stats avg(latency), max(latency), min(latency)


bucket count grep across cluster

echo "$(( `/opt/splunk/bin/splunk show cluster-status | grep Bucket\ Count | cut -d= -f2 | tr '\n' '+'` 0))"


Started, Skipped, Deferred searched (Bar Chart, Stacked):

index=_internal host="hostname" source=*metrics.log group=searchscheduler
| timechart partial=false sum(dispatched) AS Started, sum(skipped) AS Skipped
| appendcols [search index=_internal host="hostname" sourcetype=scheduler status=continued
| eval savedsearch_id_scheduled_time=savedsearch_id."-".scheduled_time
| timechart dc(savedsearch_id_scheduled_time) AS Deferred]


Scheduled search errors:
index=_internal host="hostname" source=*scheduler.log log_level=ERROR OR log_level=WARN
| cluster showcount=t
| table cluster_count, message, savedsearch_name
| sort - cluster_count
| rename cluster_count AS count message AS "Error Message" savedsearch_name AS "Scheduled search name"




http://www.brendangregg.com/blog/2014-07-25/opensnoop-for-linux.html


find all the crashing threads across all diags, start from case_<number> dir:

grep -H "Crashing\ thread" */log/*crash*| awk -F ":" '{print $5}'| sort |uniq -c


Webserver On/Off

./splunk disable webserver

./splunk enable webserver




loginBackgroundImageOption = [default| custom | none]
* Controls display of the background image of the login page.
* Defaults to "default".
  * "default" displays the Splunk default background image.
  * "custom" uses the background image defined by the backgroundImageCustomName setting.
  * "none" removes any background image on the login page. A dark background color is applied.

loginCustomBackgroundImage = <pathToMyFile or myApp:pathToMyFile>
* Customize the login page background image.
  * Supported image files include .jpg, .jpeg or .png with a maximum file size of 20Mb.
  * Landscape image is recommended, with a minimum resolution of 1024x640 pixels.
  * Using Splunk Web:
    * Upload a custom image to a manager page under General Settings.
    * The login page background image updates automatically.
  * Using the CLI or a text editor:
    * Set loginBackgroundImageOption = "custom".
    * Place custom image file in default or manual location:
      * Default destination folder: $SPLUNK_HOME/etc/apps/search/appserver/static/logincustombg.
        * Example: If your image is located at $SPLUNK_HOME/etc/apps/search/appserver/static/logincustombg/img.png, type loginCustomBackgroundImage = logincustombg/img.png.
      * Manual location: $SPLUNK_HOME/etc/apps/<myApp>/appserver/static/<pathToMyFile>, and type loginCustomBackgroundImage = <myApp:pathToMyFile>.
    * The login page background image updates automatically.
  * If no custom image is used, the default Splunk background image displays.





Identifying DMA issues

Per the webex, we identified that the datamodels were summarizing data for a longer period of time than necessary, causing a much higher load on the indexers. Additionally, we tuned the datamodels to only query the necessary indexes rather than having a more broad search.

The following tstats that we ran, identifies the sourcetypes and indexes that the datamodel has matched against. This is how we identified which indexes we wanted to refine down to in the actual datamodel query.

|tstats summariesonly=t count values(sourcetype) from datamodel=<modelname> by index

The following REST search shows what the actual query for the datamodel is and ensures that the change that was made has taken effect.

|rest /services/datamodel/acceleration | fields title search




Check for any app with a datamodel acceleration and give size on disk of summary data

|rest servicesNS/-/-/data/models
| search acceleration="1"
| table title eai:appName eai:userName
| rename eai:appName AS name| eval myDatamodel="DM_" . name . "_" . title
|map search="|rest /servicesNS/nobody/-/admin/summarization/tstats:$myDatamodel$ splunk_server=local"|table eai:acl.app,eai:acl.owner, summary.id, summary.size|rename eai:acl.app as app eai:acl.owner as owner summary.size as size summary.id as datamodel|eval sizeMB=round(size/1000000,2)|fields - size|addcoltotals sizeMB



number of active splunk pids
grep "splunkd\ pid" systeminfo.txt |wc -l

number of cpus in systeminfo.txt
grep ^processor systeminfo.txt |tail -1

dbinspect for start/endtime of buckets and sizes

| dbinspect index=main |eval rawsizeMB=round(rawSize/1024/1024,2)| eval indexedsizeMB=round(sizeOnDiskMB,2)|convert timeformat="%Y-%m-%d %H:%M:%S" ctime(endEpoch) AS end_time| convert timeformat="%Y-%m-%d %H:%M:%S" ctime(startEpoch) AS start_time| table bucketId start_time end_time state eventCount hostCount modTime path rawsizeMB indexedsizeMB sourceCount sourceTypeCount | sort state*


Remove all of one specific bucket ID in a cluster
curl -k -u <username>:<password> -X POST https://<host>:<mPort>/services/cluster/master/buckets/{bucket_id}/remove_all


http://sleeplesscoding.blogspot.com/2011/01/using-tcpdump-to-sniff-http-traffic.html

ubuntu02:~$ sudo tcpdump -c 20 -s 0 -i enp0s8 -A host 192.168.56.150  and udp port 53


if ulimits aren't sticking through /etc/security/limits.conf

https://serverfault.com/questions/544171/etc-security-limits-conf-soft-nproc-limit-appears-to-be-ignored



batch edit files in mac terminal

for file in <filename>.ext; do mv <echo for test> "$file" "prefix-$file-suffix"; done

for file in case735522-*-diag-ldxx90spkinx[5678]-*.tar.gz; do undiag "$file" username --ADpassword password; sleep 60s; history -c; done


batch edit directory names

step 1: ls -la | grep -P "db_\d{10}_\d{10}_\d{<insert number of digits in last place for bucket here>}" | awk '{print $9}' > bucketlist.txt
step 2: for file in $(cat bucketlist.txt) ; do mv "$file" "${file}_1"; done






grep -B20 -A40 -i "OOM" /var/log/message >> ~/OOM.log (RHEL/CentOS -- for Debian Based Systems use: /var/log/syslog)
grep -B20 -A40 -i "OOM Kill" /var/log/messages >> ~/OOM_Kill.log (RHEL/CentOS -- for Debian Based Systems use: /var/log/syslog)







EPS Recommendations

Index=_internal | stats count by host
 - IO intensive, doesn't use CPU/Memory Heavily
 - ~125k eps
 	events returned/amount of time/#of peers

Index = _internal
 - CPU/Memory used more
 - ~4k eps





Machine Learning

sourcetype=access_combined price=*
| eventstats max(price) as max min(price) as min range(price) as range
| eval price_proportion = if(min=max, price, (price - min) / range)
| sample proportional=price_proportion
| stats count by price price_proportion


| inputlookup autompg.csv
| where horsepower !="?"| sample partitions=2 seed=12345
| search partition_number=0
| fit  PCA * k=3 |table PC*| fit KMeans k=3 PC_*
|dedup cluster|table cluster PC_1 PC_2 PC_3

| inputlookup housing.csv
| sample partitions=3 seed=54
| search partition_number < 2
| apply scaler_model
| apply PCA_reduction
| fit DecisionTreeClassifier property_tax_rate as predicted from PC_* into PCA_classification
| `classificationstatistics(property_tax_rate,predicted)`




./btprobe -d SPLUNK_HOME/var/lib/splunk/fishbucket/splunk_private_db --file /etc/fstab --reset


./btprobe -d /apps/tools/splunkforwarder/var/lib/splunk/fishbucket/splunk_private_db --file /etc/fstab --reset


Recommended settings for large environments for Indexing/CM

Indexers:

In server.conf [clustering] change the following:

cxn_timeout = 600 – Basic timeout value for establishing a connection between the cluster nodes
send_timeout = 600 – Amount of time for a timeout with cluster nodes after a successful connection
rcv_timeout = 600 – Timeout value for waiting for the data between cluster nodes
heartbeat_period = 10 - Frequency(in secs) of heartbeat period with the cluster master

Cluster Master:

In server.conf [clustering] change the following:
heartbeat_timeout = 600 – Timeout value for when the CM determines when a cluster member is “down”
cxn_timeout = 300 – Same as above
send_timeout = 300 – Same as above
rcv_timeout = 300 – Same as above



### DETERMINE UNSUMMARIZED BUCKETS
| summarize tstats=t action=probe id=DM_Splunk_SA_CIM_Network_Traffic normid=
    [ search search (index=* OR index=_*) ((`cim_Network_Traffic_indexes`) tag=network tag=communicate)]
| eval bucket_size_gb = bucket_size / 1024 / 1024 / 1024
| rex field=bucket_id "(?<bid>^\d+?)\_(?<guid>.*$)"
| eval bucketId = index."~".bid."~".guid
| convert ctime(bucket_et) ctime(bucket_lt) ctime(summary_modtime)
| eval isSummarized = if(summary_complete=0 AND summary_hot_done=0,0,1)
| eventstats count as total_buckets count(eval(isSummarized=1)) as total_summarized count(eval(isSummarized=0)) as total_unsummarized
| eval DMA_Completion = total_summarized / total_buckets * 100
| search isSummarized=0

### DBINSPECT
| dbinspect index=<index>
| search bucketId=<bucketid>

### CM - REST BUCKET DETAILS
| rest splunk_server=local /services/cluster/master/buckets/<bucketid>
| transpose 0 header_field=title column_name="parameter"



search that shows all scheduled searches
| rest /servicesNS/-/-/saved/searches | search is_scheduled=1 | table title cron_schedule eai:acl.app



-- delete files older than 1 day ---
$SPLUNK_HOME/var/run/splunk/srtemp$ find . -ctime +1 -type d -exec rm -rf {} \;

--- remove files older 120 minutes ---
$SPLUNK_HOME/var/run/splunk/srtemp$ find . -cmin +120 -exec ls -ltr {} \;



splunkbot diag-rvaparsplindex08.tar.gz; sleep 60s; echo 930176; sleep 20s; echo y; sleep 5s; echo y; done


strace -vvv -y -p <splunk_pid>



index=0014000000kbwiuaal case_number=1169140 host=* source=*audit.log* action=update lookups|rex field=path "\/opt\/splunk\/etc\/apps\/(?<app>.*)\/lookups"|rex field=path ".*lookups\/(?<lookupfile>.*)" |table size,app,lookupfile


### CHECK SIZE OF KVSTORE COLLECTIONS
| rest splunk_server=* /services/server/introspection/kvstore/collectionstats | mvexpand data | spath input=data | rex field=ns "(?<App>.*)\.(?<Collection>.*)" | eval dbsize=size/1024/1024 | eval indexsize=totalIndexSize/1024/1024 | stats first(count) AS "Number of Objects" first(nindexes) AS Accelerations first(indexsize) AS "Acceleration Size (MB)" first(dbsize) AS "Collection Size (MB)" by App, Collection



splunk pid resource usage
sourcetype = splunk_resource_usage component=PerProcess "data.process"=splunkd | timechart span=1h max("data.fd_used") by "data.pid"

Datagen Curl
curl -d startYear=2019 -d startMonth=1 -d startDay=2 -d startHours=00 -d startMinutes=00 -d startSeconds=01 -d key=KEY -d numEvents=50000 -d encoding=ASCII -d output=file -o syslog_events-50k.txt http://datagen.splunk.com/cgi-bin/gen.cgi

./splunk list licenser-localslave
./splunk list licenser-slaves


kvstore collections via search

| rest splunk_server=local /services/server/introspection/kvstore/collectionstats
| mvexpand data
| spath input=data
| rex field=ns "(?<App>.*)\.(?<Collection>.*)"
| eval dbsize=size/1024/1024
| eval indexsize=totalIndexSize/1024/1024
| stats first(count) AS "Number of Objects" first(nindexes) AS Accelerations first(indexsize) AS "Acceleration Size (MB)" first(dbsize) AS "Collection Size (MB)" by App,Collection



Manually rebalance primaries across cluster during maintenance mode
curl -k -u admin:changeme https://master:mgmt/services/cluster/master/control/control/rebalance_primaries -X POST



Command string for watching restart status during rolling restart
while true; do /opt/splunk/bin/splunk show cluster-status | grep -A20 "Peers restarting"; date; sleep 30; done

Good setting for long maintenance mode times <12 hours
/opt/splunk/bin/splunk edit cluster-config -mode master -max_fixup_time_ms 1000


Create Table of Contents from Diag

tar tzvf diag_filename.tar.gz > diag_filename_TOC.txt


From duckie, before changing frozen time period check for which buckets should roll:
| dbinspect index=testing
| search NOT state=hot
| eval frozenTimePeriodInSecs=(86400 * 102), shouldfreeze = endEpoch + frozenTimePeriodInSecs
| where shouldfreeze < now()
| convert ctime(shouldfreeze), ctime(*Epoch)
| table splunk_server bucketId frozenTimePeriodInSecs startEpoch endEpoch shouldfreeze



diag security disclosure
Your act of attaching your diag (or any other files) to this case is an implicit statement that information contained therein can be reviewed by this engineer, and other engineers at Splunk inc.

Search for SB to identify cron schedules and locations

source="*savedsearches_debug*" | rex "enableSched\s=\s(?<enabled_schedule>\d)" | rex "disabled\s=\s(?<disabled_search>\d)" | rex "\/etc\/apps\/\w+\/default\/savedsearches.conf\s*cron_schedule\s=\s(?<default_folder_for_search>\S.+)" | rex "\/etc\/apps\/\w+\/local\/savedsearches.conf\s*cron_schedule\s=\s(?<local_folder_for_search>\S.+)" |rex "\/etc\/apps\/(?<app>[^/]+)" | search enabled_schedule=1 disabled_search=0 | table app stanza default_folder_for_search local_folder_for_search


Alfa Search Splunkbot savedsearches cron schedule

source="*savedsearches_debug*" | rex "enableSched\s=\s(?<enabled_schedule>\d)" | rex "disabled\s=\s(?<disabled_search>\d)" | rex "\/etc\/apps\/\w+\/default\/savedsearches.conf\s*cron_schedule\s=\s(?<default_folder_for_search>\S.+)" | rex "\/etc\/apps\/\w+\/local\/savedsearches.conf\s*cron_schedule\s=\s(?<local_folder_for_search>\S.+)" |rex "\/etc\/apps\/(?<app>[^/]+)" | rex "\/etc\/apps\/\w+\/local\/savedsearches.conf\s*search\s=\s(?<local_search>\S.+)" | rex "\/etc\/apps\/\w+\/default\/savedsearches.conf\s*search\s=\s(?<default_search>\S.+)" | search enabled_schedule=1 disabled_search=0 | table app stanza default_folder_for_search default_search local_folder_for_search local_search

SHC troubleshooting searches

index=_internal <list of SHC members> "Error pulling configurations from captain" NOT "consecutiveErrors=1" | timechart span=1d count by host

index=_internal <list of SHC members> "Error pushing configurations to captain" NOT "consecutiveErrors=1" | timechart span=1d count by host

index=_internal <list of SHC members> earliest="<last baseline issue>" source=*conf.log* addCommit | timechart span=2m count by host

index=_internal <list of SHC members> source=*conf.log* data.task=addCommit |stats count by data.asset_id


diff'ing files

sed -r 's/.{107}//' /Users/hkeyser/Downloads/resilient_dev.txt > /Users/hkeyser/Downloads/resilient_dev_cut.txt
diff resilient_dev_cut.txt resilient_prod_cut.txt > diff_resilient.txt



tcp pipeline creation difference

index=<replace> case_number=<replace> host=<replace> case_file=<replace> source=*metrics.log* removed_channels
                | eval out_pipeline= if(isnull(ingest_pipe),0,ingest_pipe)
                | eval ingest_pipeline= if(isnull(ingest_pipe),0,ingest_pipe)
                | eval totalpipes=round(new_channels-removed_channels)
                | timechart span=30s max(totalpipes) by host


source=*metrics.log* new_channels |timechart max(new_channels)

Average events over time

index=<insertindex> source=*http_event_collector_metrics* | timechart span=1m avg(data.num_of_events)

index=_internal source=*metrics.log* channels | timechart span=30s avg(current_size), avg(inactive_channels) by ingest_pipe

index=_internal source=*metrics.log* group=per_index_thruput series=<insertserieshere> | timechart span=30s avg(eps) by ingest_pipe

index=_internal source=*metrics.log* inactive_channels | timechart max(current_size), max(inactive_channels), max(new_channels) by ingest_pipe




grep and cut search criteria within splunkbot/diag

grep -i ssl3 splunkd.log* | cut -c37- | sort | uniq -c | sort -n

indexer restart count total number of hot buckets created
echo "$((`grep -i hotdbmanager splunkd.log | cut -c30- | sort | uniq -c | sort -n | cut -c7| tr '\n' '+'` 0))"

check total data sitting in recv-q on a netstat
echo "$((`netstat -plantu | grep tcp | grep -cv tcp6 | grep splunkd | cut -c7-12 | tr '\n' '+'` 0))"

check total data sitting in recv-q on a diag in backend of splunkbot
echo "$((`grep -i tcp systeminfo.txt | grep -v tcp6 | grep splunkd | awk '{print $2}'| tr '\n' '+'` 0))"

take output of above command and convert bytes to KB
echo "$((`grep -i tcp systeminfo.txt | grep -v tcp6 | grep splunkd | awk '{print $2}'| tr '\n' '+'` 0))" |while read B dummy; do echo $((B/1024))KB; done

check the status of the connection(established, time_wait, etc.) per process for splunk and count them

grep -i tcp systeminfo.txt | grep -v tcp6 | grep -i 'splunkd\|mongod\|python' | awk -F"[ /\\\[]+" '{print $6,$8}' | sort -n | uniq -c

diag for windows machine systeminfo.txt - grep within file for splunk ports and port status(es)

grep -i tcp systeminfo.txt | grep -v "tcp6\|127.0.0.1\|0.0.0.0\|::]\|over" | grep -w "8089\|8000\|8065\|8191\|9997\|8081\|9887\|8181\|8080\|8088" | awk -F"[ /\\\[:]+" '{print $6,$7}' | uniq -c | sort -n | sed -e 's/^[ \t]*//' | column -t

grep within file for actively used ports by process and port status

grep -i tcp systeminfo.txt | grep -v "tcp6\|127.0.0.1\|0.0.0.0\|::]\|over" | awk -F"[ /\\\[:]+" '{print $7,$8,$10}' | grep -w "8089\|8000\|8065\|8191\|9997\|8081\|9887\|8181\|8080\|8088" | sort -n | uniq -c | sed -e 's/^[ \t]*//' | column -t




check all scsi mounts
lsscsi

SPL search for corrupt buckets
| dbinspect index=_internal corruptonly=true



Total buckets vs unique buckets (must be run on CM)

| rest splunk_server=local /services/cluster/master/peers
| stats sum(bucket_count) AS bucket_count_all
| eval bucket_count = round(bucket_count_all / 1000 / 1000,2)."M"
| eval replication_factor =
    [| rest splunk_server=local /services/cluster/config
    | return $replication_factor ]
| eval unique = round(bucket_count_all / replication_factor / 1000 / 1000,2)."M"
| fields bucket_count unique
| rename bucket_count AS "Total Buckets", unique AS "Unique Buckets"


proper size analysis with summary for one directory below current location
du -ah -x --max-depth=1



find the files modified since the last number of minutes looking back and list them with modtimes

find <directory> -type f -mmin -<minutes> -exec ls -la {} \+

find /opt/splunk/ -type f -mmin -1 -exec ls -al {} \+




# lshw -class disk -class storage


from $SPLUNK_HOME/etc/users, analyze the metadata and the versions listed within them

grep -ir "version\ =\ " .
grep -ir "version\ =\ " . | awk '{print $3}'
grep -ir "version\ =\ " . | grep -v Binary | grep -v Solution | awk '{print $3}' | sort -n | uniq -c
grep -ir "version\ =\ " . | grep Binary | awk '{print $3}' | cut -b 1,2 --complement | cut -d "/" -f 1 | sort -n | uniq -c | awk '{print $2}'
grep -air "version\ =\ " .
cat `grep -ir "version\ =\ " | grep Binary | cut -d " " -f 3` | strings -af | grep "version\ =\ 7.3.2"







bulk extract and directory renaming

extract and rename the directories according to hostname rather than <host.domain.mynetwork.com>

for file in *.tgz; do fileOut=$(echo $file | cut -d '.' -f1 | cut -d '-' -f1); tar -xvzf $fileOut*.tgz; mv opt $fileOut; done


no subdirectories in the tarball

for file in *.tar.gz; do fileOut=$(echo $file | cut -d '.' -f1 | cut -d '-' -f8-9); tar -xvzf *$fileOut.tar.gz; done



batch flamegraphs oneliner

Make sure that the directory(-ies) have been created for the new case under your preferred location(s)

Directories required under flamegraph:

flamegraph
----Case number
--------pstacks
--------pstacksOutput



verify the names of the files for the next step

for dir in ~/flamegraph/<yourcasenumber>/pstacks/*; do dirOut=$(echo $dir | cut -d '/' -f 7); echo $dirOut; done

run the batch flamegraph

for dir in ~/flamegraph/<yourcasenumber>/pstacks/*; do dirOut=$(echo $dir | cut -d '/' -f 7); echo $dirOut; ~/flamegraph/FlameGraph-master/getstacks.py --title $dirOut -F -v ~/flamegraph/<yourcasenumber>/pstacks/$dirOut/<anySubDirectoriesFromThePstackCapture>/ > ~/flamegraph/<yourcasenumber>/pstacksOutput/$dirOut.svg; sleep 1s; done

****You may need to edit the cut -f number to a higher/lower number depending on the depth of the actual hostnames in your folder





More Flamegraph Info

https://github.com/brendangregg/FlameGraph


Consistent Palette

If you use the --cp option, it will use the $colors selection and randomly generate the palette like normal. Any future flamegraphs created using the --cp option will use the same palette map. Any new symbols from future flamegraphs will have their colors randomly generated using the $colors selection.

If you don't like the palette, just delete the palette.map file.

This allows your to change your colorscheme between flamegraphs to make the differences REALLY stand out.

Example:

Say we have 2 captures, one with a problem, and one when it was working (whatever "it" is):

cat working.folded | ./flamegraph.pl --cp > working.svg
# this generates a palette.map, as per the normal random generated look.

cat broken.folded | ./flamegraph.pl --cp --colors mem > broken.svg
# this svg will use the same palette.map for the same events, but a very
# different colorscheme for any new events.




getstacks.py can be used to grep for more information within the stack

getstacks.py -I <stackdirectory>/*out | grep here






Windows Stuff

sfc /scannow
sfc /verify

dism - basically SFC but does a deeper dive






Search Head Clustering Golden Configs


[shclustering]
cxn_timeout = 120
send_timeout = 120
rcv_timeout = 120
cxn_timeout_raft = 4
send_timeout_raft = 10
rcv_timeout_raft = 10
election_timeout_ms = 120000
enable_jobs_data_lite = true
executor_workers = 30
replication_factor = 2
heartbeat_timeout = 120





#####
DBINSPECT
####

#  basic which coverts EPOCH
|dbinspect index=indexname | convert ctime(endEpoch) AS earliestTime | convert ctime(startEpoch) AS latestTime

# same but tables it:
|dbinspect index=indexname | convert ctime(endEpoch) AS earliestTime | convert ctime(startEpoch) AS latestTime | table bucketId, earliestTime,latestTime

##### to show index stats
| dbinspect index=*
 | search tsidxState="full" bucketId=*
     | eval ageDays=round((endEpoch-startEpoch)/84000,10)
 | stats min(startEpoch) as MinStartTime max(startEpoch) as MaxStartTime min(endEpoch) as MinEndTime max(endEpoch) as MaxEndTime max(hostCount) as MaxHosts max(sourceTypeCount) as MaxSourceTypes sum(eventCount) as TotalEvents sum(rawSize) as rawSizeBytes sum(sizeOnDiskMB) as sizeOnDiskBytes values(ageDays) as ageDays dc(bucketId) as countBuckets by index bucketId, state
     | where ageDays<90 AND ageDays>0.0000000000
     | eval sizeOnDiskBytes=round(sizeOnDiskBytes*pow(1024,2))
     | eval dailyDisk=round(sizeOnDiskBytes/ageDays,5)
     | eval dailyRaw=round(rawSizeBytes/ageDays,5)
     | eval dailyEventCount=round(TotalEvents/ageDays)
 | table index bucketId state dailyDisk ageDays rawSizeBytes, sizeOnDiskBytes TotalEvents PercentSizeReduction dailyRaw dailyEventCount ageDays
 | stats sum(dailyDisk) as dailyBDiskBucket, values(ageDays), sum(dailyRaw) as dailyBRaw sum(dailyEventCount) as dailyEvent, avg(dailyDisk) as dailyBDiskAvg, avg(dailyRaw) as dailyBRawAvg, avg(dailyEventCount) as dailyEventAvg, dc(bucketId) as countBucket by index, state, ageDays
     | eval bPerEvent=round(dailyBDiskBucket/dailyEvent)
     | eval bPerEventRaw=round(dailyBRaw/dailyEvent)
 | table dailyBDiskBucket index ageDays dailyEvent bPerEvent dailyBRaw bPerEventRaw state
     | sort ageDays
 | stats sum(dailyBDiskBucket) as Vol_totDBSize, avg(dailyBDiskBucket) as Vol_avgDailyIndexed, max(dailyBDiskBucket) as Vol_largestVolBucket, avg(dailyEvent) as avgEventsPerDay, avg(bPerEvent) as Vol_avgVolPerEvent, avg(dailyBRaw) as Vol_avgDailyRawVol, avg(bPerEventRaw) as Vol_avgVolPerRawEvent, range(ageDays) as rangeAge by index, state
     | foreach Vol_* [eval <<FIELD>>=if(<<FIELD>> >= pow(1024,3), tostring(round(<<FIELD>>/pow(1024,3),3))+ " GB", if(<<FIELD>> >= pow(1024,2), tostring(round(<<FIELD>>/pow(1024,2),3))+ " MB", if(<<FIELD>> >= pow(1024,1), tostring(round(<<FIELD>>/pow(1024,2),3))+ " KB", tostring(round(<<FIELD>>)) + " bytes")))]
     | rename Vol_* as *
     | eval comb="Index Avg/day: " + avgDailyIndexed + "," + "Raw Avg/day: " + avgDailyRawVol + "," + "DB Size: " + totDBSize + "," + "Per Event Avg/Vol: " + avgVolPerEvent + "," + "Retention Range: " + tostring(round(rangeAge))
     | eval comb = split(comb,",")
 | xyseries index state comb
 | table index hot warm cold




Search for per process memory utilization

source=*resource* component=PerProcess | eval process = 'data.process' | eval args= 'data.args' | eval sid = 'data.search_props.sid' | eval process_class = case( process=="mongod", "KV store", process=="splunk-optimize","index service", process=="sh" OR process=="ksh" OR process=="bash" OR like(process,"python%") OR process=="powershell","scripted input")| eval process_class = case( process=="splunkd" AND ((like(args,"-p %start%") AND NOT like(args,"%process-runner%")) OR args=="service"),"splunkd server", process=="splunkd" AND isnotnull(sid), "search", process=="splunkd" AND (like(args,"fsck%") OR like(args,"recover-metadata%") OR like(args,"cluster_thing")),"index service", process=="splunkd" AND args=="instrument-resource-usage","scripted input", (like(process,"python%") AND like(args,"%/appserver/mrsparkle/root.py%")) OR like(process,"splunkweb"),"Splunk Web", isnotnull(process_class), process_class)| eval process_class = if(isnull(process_class),"other",process_class) | timechart span=5m avg(data.mem_used) as Memory_Used by process_class








Helpful SHC searches to run

A.) What is the latest common bundle id on the SH? Run the following search on the SH logging the WARN msg (if SHC, run it on the SHC captain since the captain sends the bundle to the indexers):

| rest splunk_server=local /services/search/distributed/bundle-replication-files | convert ctime(timestamp) as timestamp| eval sizeMB= round(size/1024/1024,2) | table splunk_server filename location size sizeMB timestamp title| rename title as "bundle version" | join splunk_server [| rest splunk_server=local /services/configs/conf-distsearch | search maxBundleSize=* | table splunk_server maxBundleSize | rename maxBundleSize as "maxBundleSize (distsearch.conf)"]

# note: since you are unable to log directly into a specific SH, you can log into the SHC captain from the cli and run the search from there:

splunk search '| rest splunk_server=local /services/search/distributed/bundle-replication-files | convert ctime(timestamp) as timestamp| eval sizeMB= round(size/1024/1024,2) | table splunk_server filename location size sizeMB timestamp title| rename title as "bundle version" | join splunk_server [| rest splunk_server=local /services/configs/conf-distsearch | search maxBundleSize=* | table splunk_server maxBundleSize | rename maxBundleSize as "maxBundleSize (distsearch.conf)"] '

From the results look at the latest timestamp and copy the "bundle version" id which we will use in the next search. As an example, we will use a bundle version of 8748801169886468464.

B.) Determine which peer(s) do not have that latest bundle. Run the following search on the SH logging the WARN msg (if SHC, run it on the SHC captain since the captain sends the bundle to the indexers):

| rest splunk_server=local /services/search/distributed/peers
| rex field=bundle_isIndexing "\w\s-\s(?<truefalse>\w+)"
| stats values(bundle_versions) as "bundle_versions" dc(bundle_versions) as "bundle versions on indexer" by splunk_server host status version guid
| rename version as "indexer version" guid as "indexer guid" host as indexer| search bundle_versions!=8748801169886468464

#note: the messages tab in the SH should also be indicating which peer(s) are having an issue




search for avg tcpout thruput per pipeline and additional stats

|stats sum(tcp_avg_thruput) median(tcp_avg_thruput) avg(tcp_avg_thruput) max(tcp_avg_thruput) min(tcp_avg_thruput) by ingest_pipe
    |eval avg(KB)='avg(tcp_avg_thruput)'
    |eval sum(KB)='sum(tcp_avg_thruput)'
    |eval median(KB)='median(tcp_avg_thruput)'
    |eval max(KB)='max(tcp_avg_thruput)'
    |eval min(KB)='min(tcp_avg_thruput)'
|table ingest_pipe,sum(KB),median(KB),avg(KB),max(KB),min(KB)

search for avg tcpout thruput and chart over time

|timechart span=30s avg(tcp_avg_thruput) by ingest_pipe


Long Event Check:

Sourcetype=splunkd AggregatorMiningProcessor OR LineBreakingProcessor OR DateParserVerbose WARN | rex "(?<type>(Failed to parse timestamp|suspiciously far away|outside of the acceptable time window|too far away from the previous|Accepted time format has changed|Breaking event because limit of \d+|Truncating line because limit of \d+))" | eval type=if(isnull(type),"unknown",type) | rex "source=(?<eventsource>[^\|]*)\|host=(?<eventhost>[^\|]*)\|(?<eventsourcetype>[^\|]*)\|(?<eventport>[^\s]*)" | eval eventsourcetype=if(isnull(eventsourcetype),data_sourcetype,eventsourcetype) | stats count dc(eventhost) values(eventsource) dc(eventsource) values(type) values(index) by component eventsourcetype | sort -count







useACK vs tcpoutQueue search (requires TcpOutputProc component in DEBUG)

index=<customerindex> case_number=<casenumber> case_file=<diagname> sourcetype=splunkd component=TcpOutputProc waitingAckQ
| rex "(?<ackWaitQueue>\_waitingAckQ\.size\(\))=(?<ackQsize>\d*)"
|timechart span=30s max(ackQsize), avg(ackQsize)
|appendcols [search index=<customerindex> case_number=<casenumber> host=<host> case_file=<diagname> sourcetype=metrics
                        group=queue name=tcpout_splunk
                        | eval max=if(isnotnull(max_size_kb),max_size_kb,max_size)
                        | eval curr=if(isnotnull(current_size_kb),current_size_kb,current_size)
                        | eval fill_perc=round((curr/max)*100,2)
                        | timechart span=30s max(fill_perc) by name]







Cluster Master (CM) task priorities

Real time searches
Initial Indexing (UDP>TCP>LOCAL)
Searching (Adhoc/API>Scheduled)
Replications (SF > RF)
Rebalance/Remove Excess Buckets




Get size on disk for cached SmartStore indexes

|dbinspect cached=t index=<yourindex> | stats sum(sizeOnDisk)



https://www.sslshopper.com/article-most-common-openssl-commands.html

OpenSSL syntax for checking cert expiration

openssl x509 -in certificate.crt -text -noout







Smart Store Troubleshooting

#download rate
source=*metrics*  index=_internal
group=cachemgr_download |timechart per_second(kb) as kbps by host |eval ceiling=30000


2) Number of queued download jobs:

source=*metrics*  index=_internal group=cachemgr_download
|timechart median(queued) as queued by  host |eval ceiling=20

3)how many searches  Searches Are Slow

index=_internal   source=*/splunkd_access.log | rex field=uri "/services/admin/cacheman/bid|(?<bid>[^|]*)|/close" | search uri=*/close* | eval mytime=strftime(_time, "%Y-%m-%d %H:%M:%S") | stats last(_time) as _time count as buckets, sum(miss_ms) as miss_ms sum(search_ms) as search_ms, min(mytime) as issuetime by sid | fillnull value=0 search_ms | eval overheadRatio=(miss_ms/search_ms) | eval miss_ms_per_bucket=miss_ms/buckets | fillnull value=0 overheadRatio | eval searchSpeed=if(overheadRatio > 2,"slow","fast") | timechart count by searchSpeed

4)age of bucket searches
index=_audit source=*audit.log* action=remote_bucket_download
info=completed
|fields  local_dir kb elapsed_ms files cache_id host
|rex field=local_dir "\/splunk\/(?<idx>[^\/]+)\/\w+\/db_(?<lt>[^_]+)_(?<et>[^_]+)_(?<seq>[^_]+)_(?<guid>[^\"]+)"
| eval gbps=kb/1024/1024
|eval age=round((_time-lt)/60/60/24)
|bucket span=10 age
|timechart minspan=10s sum(gbps) by age usenull=false limit=10

5) Cache Hit and Miss
index=_internal source=*metrics.log* group=cachemgr_bucket
| timechart minspan=10s  sum(cache_hit) sum(cache_miss)


more helpful grep for startup info (ulimits, thp, etc)
egrep -a "(loader - Detected|Limiting REST|Limit: open|Limit: user|Limit: data segment|Linux transparent| My GUID)" splunkd.*
